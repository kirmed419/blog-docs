<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cross Validation, and the Train/Test Split | Data Guide</title>
<meta name="keywords" content="machine learning, concept">
<meta name="description" content="Learn about cross validation, the train/test split and how it is implemented in Python.">
<meta name="author" content="Kirouane Mohammed">
<link rel="canonical" href="https://kirmed419.github.io/blog-docs/guides/crossva/">
<link crossorigin="anonymous" href="/blog-docs/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://kirmed419.github.io/blog-docs/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://kirmed419.github.io/blog-docs/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://kirmed419.github.io/blog-docs/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://kirmed419.github.io/blog-docs/apple-touch-icon.png">
<link rel="mask-icon" href="https://kirmed419.github.io/blog-docs/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Cross Validation, and the Train/Test Split" />
<meta property="og:description" content="Learn about cross validation, the train/test split and how it is implemented in Python." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kirmed419.github.io/blog-docs/guides/crossva/" /><meta property="article:section" content="guides" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cross Validation, and the Train/Test Split"/>
<meta name="twitter:description" content="Learn about cross validation, the train/test split and how it is implemented in Python."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Guides",
      "item": "https://kirmed419.github.io/blog-docs/guides/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cross Validation, and the Train/Test Split",
      "item": "https://kirmed419.github.io/blog-docs/guides/crossva/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cross Validation, and the Train/Test Split",
  "name": "Cross Validation, and the Train\/Test Split",
  "description": "Learn about cross validation, the train/test split and how it is implemented in Python.",
  "keywords": [
    "machine learning", "concept"
  ],
  "articleBody": "Cross-Validation and Training/Testing Split Training/Testing Split Concept: The training/testing split is a fundamental concept in machine learning used to evaluate the performance of a model. It involves dividing your dataset into two parts:\nTraining Set: This subset of the data is used to train the machine learning model. The model learns from this data and adjusts its parameters accordingly.\nTesting Set: This subset is used to evaluate the model’s performance. After the model has been trained, it is tested on this unseen data to assess how well it generalizes to new, unseen examples.\nPurpose:\nModel Evaluation: Helps in assessing how well the model performs on data it hasn’t seen before. Overfitting Detection: Assists in detecting if the model is overfitting, i.e., if it performs well on training data but poorly on unseen data. Example in Python:\nfrom sklearn.model_selection import train_test_split from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score # Load dataset data = load_iris() X = data.data y = data.target # Split the data into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Train a model model = LogisticRegression(max_iter=200) model.fit(X_train, y_train) # Make predictions y_pred = model.predict(X_test) # Evaluate the model accuracy = accuracy_score(y_test, y_pred) print(f\"Accuracy: {accuracy:.2f}\") Cross-Validation Explained Conceptually\nCross-validation is a technique used to evaluate the performance of a machine learning model. It helps ensure that the model generalizes well to new, unseen data. Let’s break it down conceptually using a metaphor and examples.\nMetaphor: The Baking Contest Imagine you’re entering a baking contest where the judges are very particular about the quality of your cakes. You want to make sure your cake recipe is reliable and consistently good. To do this, you might try the following steps:\nDivide and Conquer: Instead of just baking one cake and hoping it’s perfect, you decide to bake several cakes using the same recipe. You divide your time into different batches, each batch representing a different set of ingredients and baking conditions.\nTaste Tests: For each cake, you have a panel of friends taste it. Each friend rates the cake on various factors like texture, flavor, and sweetness. You rotate which friend tastes which cake so that each cake gets evaluated multiple times.\nAverage Ratings: After all the cakes are tasted, you average the ratings to get a sense of how well your recipe performs overall. This gives you confidence that your recipe is consistently good and not just a fluke.\nIn this metaphor:\nThe cakes represent different subsets of your data. The taste tests represent the evaluation of your model’s performance on different subsets. The average ratings give you a measure of how well your recipe (or model) is likely to perform in general. Example: The Data and Model Let’s say you have a dataset of 1000 samples, and you want to evaluate a machine learning model. Here’s how cross-validation might work:\nK-Fold Cross-Validation:\nDivide the Dataset: You split the dataset into K equally sized subsets (or folds). For example, if K=5, you divide the data into 5 subsets. Train and Test: You then train your model on K-1 of these subsets and test it on the remaining subset. You repeat this process K times, each time using a different subset as the test set and the remaining K-1 subsets as the training set. Average Results: After evaluating the model on all K subsets, you average the performance metrics (like accuracy or mean squared error) to get a final performance estimate. This method ensures that every sample in the dataset is used for both training and testing, which helps in obtaining a more robust measure of model performance.\nLeave-One-Out Cross-Validation (LOOCV):\nOne-by-One Testing: In this variant, if you have 1000 samples, you train your model 1000 times. Each time, you leave out one sample as the test set and use the remaining 999 samples as the training set. Evaluate Performance: The performance metrics are then averaged across all 1000 iterations. LOOCV is especially useful when you have a small dataset but can be computationally expensive for large datasets.\nSummary Cross-validation helps in assessing how well a model will perform on new, unseen data by training and evaluating it multiple times on different subsets of the dataset. It provides a more reliable estimate of model performance compared to a single train-test split. By ensuring that every data point gets to be in a test set at least once, cross-validation helps in mitigating issues related to overfitting and provides a better understanding of model robustness.\n",
  "wordCount" : "753",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Kirouane Mohammed"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://kirmed419.github.io/blog-docs/guides/crossva/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data Guide",
    "logo": {
      "@type": "ImageObject",
      "url": "https://kirmed419.github.io/blog-docs/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://kirmed419.github.io/blog-docs/" accesskey="h" title="Data Guide (Alt + H)">Data Guide</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://kirmed419.github.io/blog-docs/guides" title="Guides">
                    <span>Guides</span>
                </a>
            </li>
            <li>
                <a href="https://kirmed419.github.io/blog-docs/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://kirmed419.github.io/blog-docs/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://kirmed419.github.io/blog-docs/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Cross Validation, and the Train/Test Split
    </h1>
    <div class="post-description">
      Learn about cross validation, the train/test split and how it is implemented in Python.
    </div>
    <div class="post-meta">Kirouane Mohammed

</div>
  </header> 
  <div class="post-content"><h2 id="cross-validation-and-trainingtesting-split">Cross-Validation and Training/Testing Split<a hidden class="anchor" aria-hidden="true" href="#cross-validation-and-trainingtesting-split">#</a></h2>
<h3 id="trainingtesting-split">Training/Testing Split<a hidden class="anchor" aria-hidden="true" href="#trainingtesting-split">#</a></h3>
<p><strong>Concept:</strong>
The training/testing split is a fundamental concept in machine learning used to evaluate the performance of a model. It involves dividing your dataset into two parts:</p>
<ol>
<li>
<p><strong>Training Set:</strong> This subset of the data is used to train the machine learning model. The model learns from this data and adjusts its parameters accordingly.</p>
</li>
<li>
<p><strong>Testing Set:</strong> This subset is used to evaluate the model&rsquo;s performance. After the model has been trained, it is tested on this unseen data to assess how well it generalizes to new, unseen examples.</p>
</li>
</ol>
<p><strong>Purpose:</strong></p>
<ul>
<li><strong>Model Evaluation:</strong> Helps in assessing how well the model performs on data it hasn&rsquo;t seen before.</li>
<li><strong>Overfitting Detection:</strong> Assists in detecting if the model is overfitting, i.e., if it performs well on training data but poorly on unseen data.</li>
</ul>
<p><strong>Example in Python:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_iris
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load dataset</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> load_iris()
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Split the data into training and testing sets</span>
</span></span><span style="display:flex;"><span>X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Train a model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> LogisticRegression(max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">200</span>)
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make predictions</span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Evaluate the model</span>
</span></span><span style="display:flex;"><span>accuracy <span style="color:#f92672">=</span> accuracy_score(y_test, y_pred)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>) 
</span></span></code></pre></div><p><strong>Cross-Validation Explained Conceptually</strong></p>
<p>Cross-validation is a technique used to evaluate the performance of a machine learning model. It helps ensure that the model generalizes well to new, unseen data. Let’s break it down conceptually using a metaphor and examples.</p>
<h3 id="metaphor-the-baking-contest">Metaphor: The Baking Contest<a hidden class="anchor" aria-hidden="true" href="#metaphor-the-baking-contest">#</a></h3>
<p>Imagine you&rsquo;re entering a baking contest where the judges are very particular about the quality of your cakes. You want to make sure your cake recipe is reliable and consistently good. To do this, you might try the following steps:</p>
<ol>
<li>
<p><strong>Divide and Conquer:</strong> Instead of just baking one cake and hoping it&rsquo;s perfect, you decide to bake several cakes using the same recipe. You divide your time into different batches, each batch representing a different set of ingredients and baking conditions.</p>
</li>
<li>
<p><strong>Taste Tests:</strong> For each cake, you have a panel of friends taste it. Each friend rates the cake on various factors like texture, flavor, and sweetness. You rotate which friend tastes which cake so that each cake gets evaluated multiple times.</p>
</li>
<li>
<p><strong>Average Ratings:</strong> After all the cakes are tasted, you average the ratings to get a sense of how well your recipe performs overall. This gives you confidence that your recipe is consistently good and not just a fluke.</p>
</li>
</ol>
<p>In this metaphor:</p>
<ul>
<li><strong>The cakes</strong> represent different subsets of your data.</li>
<li><strong>The taste tests</strong> represent the evaluation of your model&rsquo;s performance on different subsets.</li>
<li><strong>The average ratings</strong> give you a measure of how well your recipe (or model) is likely to perform in general.</li>
</ul>
<h3 id="example-the-data-and-model">Example: The Data and Model<a hidden class="anchor" aria-hidden="true" href="#example-the-data-and-model">#</a></h3>
<p>Let’s say you have a dataset of 1000 samples, and you want to evaluate a machine learning model. Here’s how cross-validation might work:</p>
<ol>
<li>
<p><strong>K-Fold Cross-Validation:</strong></p>
<ul>
<li><strong>Divide the Dataset:</strong> You split the dataset into <strong>K</strong> equally sized subsets (or folds). For example, if K=5, you divide the data into 5 subsets.</li>
<li><strong>Train and Test:</strong> You then train your model on <strong>K-1</strong> of these subsets and test it on the remaining subset. You repeat this process <strong>K</strong> times, each time using a different subset as the test set and the remaining <strong>K-1</strong> subsets as the training set.</li>
<li><strong>Average Results:</strong> After evaluating the model on all K subsets, you average the performance metrics (like accuracy or mean squared error) to get a final performance estimate.</li>
</ul>
<p>This method ensures that every sample in the dataset is used for both training and testing, which helps in obtaining a more robust measure of model performance.</p>
</li>
<li>
<p><strong>Leave-One-Out Cross-Validation (LOOCV):</strong></p>
<ul>
<li><strong>One-by-One Testing:</strong> In this variant, if you have 1000 samples, you train your model 1000 times. Each time, you leave out one sample as the test set and use the remaining 999 samples as the training set.</li>
<li><strong>Evaluate Performance:</strong> The performance metrics are then averaged across all 1000 iterations.</li>
</ul>
<p>LOOCV is especially useful when you have a small dataset but can be computationally expensive for large datasets.</p>
</li>
</ol>
<h3 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h3>
<p>Cross-validation helps in assessing how well a model will perform on new, unseen data by training and evaluating it multiple times on different subsets of the dataset. It provides a more reliable estimate of model performance compared to a single train-test split. By ensuring that every data point gets to be in a test set at least once, cross-validation helps in mitigating issues related to overfitting and provides a better understanding of model robustness.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://kirmed419.github.io/blog-docs/tags/machine-learning/">machine learning</a></li>
      <li><a href="https://kirmed419.github.io/blog-docs/tags/concept/">concept</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://kirmed419.github.io/blog-docs/">Data Guide</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
